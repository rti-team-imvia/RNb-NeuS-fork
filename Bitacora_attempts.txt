bearPNG (2024/09/29) SUCESS!: Data by authors with normals,albedo,mask,mask_normal_uncertainty, and cameras.npz
failed_exps/head_cs_3D_in_30iterations (2024/09/26) SUCESS in code FAILURE in results. But is normal because it was a test with 30 iterations
failed_exps/head_cs_3D_in(2024/09/28): FAILURE!: Our data with albedo(visually different than authors, myabe because they are not scaled as they did?), masks(correct?), normals(Rams method, visually similar to masks authors, but we might try the author's methods for normals), no masks_uncertainty 

failed_exps/head_cs_3D_in_na (2024/09/30) Failed! (no albedo, normals by Ram's method):
We are going to try to run head_cs_3D_in(2024/09/28) but now without albedo conserving our method for normals.
python exp_runner.py --mode train_rnb --conf ./confs/wmask_rnb_noalbedo.conf --case head_cs_3D_in_na --no_albedo

failed_exps/head_cs_3D_in_na_na (2024/09/30) Failed!(no albedo,normals authors method):
We are going to try using authors method for generating normals (SDM repository) and we won't use "reflectance maps" or albedos.
python exp_runner.py --mode train_rnb --conf ./confs/wmask_rnb_noalbedo.conf --case head_cs_3D_in_na_na --no_albedo

failed_exps/head_cs_3D_in_rm (2024/10/03) (albedo corrected to original


######
######
2024/10/08
RAM organized the cameras.npz file so it should be now good?
I am using the albedo and masks as authors did

===> Attempt 001 (2024/10/08) Input on C:\Users\X-RTI\Documents\repos\RNb-NeuS-fork\data\head_cs_001 Output on: C:\Users\X-RTI\Documents\repos\RNb-NeuS-fork\exp\head_cs_001\wmask_rnb
=>Masks: Generated on LIGHT.jpg
=>Normals: SDM_out\normal.png unchanged
=>Albedo: SDM_out\baseColor.png unchanged
=>cameras.npz: Second version generated by RAM
Result: Failed in running
Comments: It seems like Ram's cameras.npz file is not working


===> Attempt 002 (2024/10/08) Input on C:\Users\X-RTI\Documents\repos\RNb-NeuS-fork\data\head_cs_002 Output on: C:\Users\X-RTI\Documents\repos\RNb-NeuS-fork\exp\head_cs_002\wmask_rnb
=>Hypotesis: I could use the example cameras.npz file used in bear but with my data.
=>Masks: Generated on LIGHT.jpg
=>Normals: SDM_out\normal.png unchanged
=>Albedo: SDM_out\baseColor.png unchanged
=>cameras.npz: Same as Bear example.
Result: Failed
Comments: it seems like the Bear cameras.npz file is just for Bear. But what about if the number of images is the same as in bear?


===> Attempt 003 (2024/10/08) Input on C:\Users\X-RTI\Documents\repos\RNb-NeuS-fork\data\head_cs_003 Output on: C:\Users\X-RTI\Documents\repos\RNb-NeuS-fork\exp\head_cs_003\wmask_rnb
=>Data: I removed the files 004, 009, 015 and 023 in order to have 20 images only. Then renamed then so I had from 000.png to 019.png for all masks, normals and albedo. At least the code ran because of that.
=>Hypotesis: Using the same number of images might allow to use the same cameras.npz file used in the example bear.
=>Masks: Generated on LIGHT.jpg
=>Normals: SDM_out\normal.png unchanged
=>Albedo: SDM_out\baseColor.png unchanged
=>cameras.npz: Same as Bear example.
Result: It did not finished
Comments: For some reason the computer rebooted so I will run again the code and I will give another comments and results
Results: This time the output mesh is noise, so basically the software won't give anything as mesh. However if we go to the folder "validations_fine" we can see that the model
it is learning something, or at least this folder seems to be showing us that, the question is "why it can not generate the mesh?"
Comments: Next step could be debug the code so we can see what is the problem with the mesh. However at this point I started to replicate the full process of preprocessing using bearPNG.
The hypotesis is if I am capable to reproduce the pre-processing in the bearPNG from the original data then I can use this same procedure in our data.

===> bearPNG 001 (2024/10/10) Input original data from RNb-NeuS bearPNG Output in C:/Users/Deivid/Documents/rti-data/Palermo_3D/3D/out/bearPNG_001
Results: Worked as expected. So the Cluster can be used to perform the training normally.

===> bearPNG 002 (2024/10/10) Output in C:/Users/Deivid/Documents/rti-data/Palermo_3D/3D/out/bearPNG_002
=>Data: 1) Original bearPNG data from DiLiGenT-MV. 2) Used SDM-UniPS to get normals and albedo using their masks
=>Hypotesis: If the reconstruction of bearPNG without reflectance scaling is as good as bearPNG with reflectance scaling then we could skip this scaling process too in our data, right?.
=>Masks: Same as DiLiGenT-MV (I could swear it is the same as RNb-NeuS too, why bother to use another method, right?)
=>Normals: Output of SDM-UniPS performed by me (they are really close to the ones used by RNb-NeuS). The slightly difference might be for the 10 images RNb-NeuS took when using SDM-UniPS (different than mine I imagine)
=>Albedo: Output of SDM-UniPS performed by me, they are not scaled but they are really similar. When using compare_images_similarities.py in 000.png I have: MSE: 11.06, Coordinates: (320, 166), RNB-NeuS Pixel Value: [ 69 115  40], Ours: [ 80 131  43],	Difference Pixel Value: [11 16  3]
=>cameras.npz: File given by RNb-NeuS
=>Results: When comparing bearPNG_001 (bearPNG) and current bearPNG_002 we can visually conclude that we get almost the same mesh (also the validations_fine shows a similar output)
=>Comments: We can assume that the reflectance scaling is not neccesary although bearPNG is a really simple mesh in therms of color (single color) so perhaps head_cs might need scaling. On the other hand authors say:  "if the cameraâ€™s response and the illumi-
nation were known i.e., a calibrated PS method was used in Step 1 (Computing normals and reflectance), then the reflectance would be determined without scale ambiguity and this step could be skipped"

===> head_cs_004 (2024/10/12) Input: F:\dvd\Palermo_3D\3D\in\head_cs_3D_in_004. Output: F:\dvd\Palermo_3D\3D\out\head_cs_004
=>Data: I used all the data, hoping the code does not crash this time with the new content of cameras.npz
=>Hypothesis: Replacing the scale matrices in cameras.npz file with the identidy matrix might let the code to run 
=>Masks: Generated on LIGHT.jpg
=>Normals: SDM_out\normal.png unchanged (However before we did not use SDM with masks so from now on the background was removed)
=>Albedo: SDM_out\baseColor.png unchanged (However before we did not use SDM with masks so from now on the background was removed)
=>camera.npz: Created with wfsm and then using sfm_camera_txt_file_to_npz.py
=>Results: The new cameras.npz file ran without problems so we can use it as input, it gave a mesh as output too. However the results are noise?, based on the validations_fine it seems like it could improve with more epochs so I changed to 600K iterations.
=>Comments: Waiting for the results after 600K
